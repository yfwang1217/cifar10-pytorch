{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vH3A6h5noQa",
        "outputId": "71a6fbe0-bba0-4a2a-bf88-93b93bf9b062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "(50000, 3072) (50000,)\n",
            "train_data\n",
            "[[ 59  43  50 ... 140  84  72]\n",
            " [154 126 105 ... 139 142 144]\n",
            " [255 253 253 ...  83  83  84]\n",
            " ...\n",
            " [ 35  40  42 ...  77  66  50]\n",
            " [189 186 185 ... 169 171 171]\n",
            " [229 236 234 ... 173 162 161]]\n",
            "test_data\n",
            "[[255 252 253 ... 173 231 248]\n",
            " [127 126 127 ... 102 108 112]\n",
            " [116  64  19 ...   7   6   5]\n",
            " ...\n",
            " [ 35  40  42 ...  77  66  50]\n",
            " [189 186 185 ... 169 171 171]\n",
            " [229 236 234 ... 173 162 161]]\n",
            "Total number of parameters is: 1753258\n",
            "Epoch [1/50]\n",
            "Epoch [1/50], Loss: 1.4171\n",
            "Accuracy of the model on the test images: 54.08%\n",
            "Epoch [2/50]\n",
            "Epoch [2/50], Loss: 0.9095\n",
            "Accuracy of the model on the test images: 68.23%\n",
            "Epoch [3/50]\n",
            "Epoch [3/50], Loss: 0.7284\n",
            "Accuracy of the model on the test images: 76.62%\n",
            "Epoch [4/50]\n",
            "Epoch [4/50], Loss: 0.6275\n",
            "Accuracy of the model on the test images: 79.64%\n",
            "Epoch [5/50]\n",
            "Epoch [5/50], Loss: 0.5498\n",
            "Accuracy of the model on the test images: 81.88%\n",
            "Epoch [6/50]\n",
            "Epoch [6/50], Loss: 0.4987\n",
            "Accuracy of the model on the test images: 85.58%\n",
            "Epoch [7/50]\n",
            "Epoch [7/50], Loss: 0.4500\n",
            "Accuracy of the model on the test images: 82.4%\n",
            "Epoch [8/50]\n",
            "Epoch [8/50], Loss: 0.4152\n",
            "Accuracy of the model on the test images: 84.88%\n",
            "Epoch [9/50]\n",
            "Epoch [9/50], Loss: 0.3878\n",
            "Accuracy of the model on the test images: 86.64%\n",
            "Epoch [10/50]\n",
            "Epoch [10/50], Loss: 0.3561\n",
            "Accuracy of the model on the test images: 85.56%\n",
            "Epoch [11/50]\n",
            "Epoch [11/50], Loss: 0.3364\n",
            "Accuracy of the model on the test images: 88.96%\n",
            "Epoch [12/50]\n",
            "Epoch [12/50], Loss: 0.3150\n",
            "Accuracy of the model on the test images: 90.45%\n",
            "Epoch [13/50]\n",
            "Epoch [13/50], Loss: 0.2963\n",
            "Accuracy of the model on the test images: 90.13%\n",
            "Epoch [14/50]\n",
            "Epoch [14/50], Loss: 0.2820\n",
            "Accuracy of the model on the test images: 91.07%\n",
            "Epoch [15/50]\n",
            "Epoch [15/50], Loss: 0.2596\n",
            "Accuracy of the model on the test images: 91.54%\n",
            "Epoch [16/50]\n",
            "Epoch [16/50], Loss: 0.2458\n",
            "Accuracy of the model on the test images: 91.17%\n",
            "Epoch [17/50]\n",
            "Epoch [17/50], Loss: 0.2350\n",
            "Accuracy of the model on the test images: 92.12%\n",
            "Epoch [18/50]\n",
            "Epoch [18/50], Loss: 0.2227\n",
            "Accuracy of the model on the test images: 93.29%\n",
            "Epoch [19/50]\n",
            "Epoch [19/50], Loss: 0.2091\n",
            "Accuracy of the model on the test images: 92.5%\n",
            "Epoch [20/50]\n",
            "Epoch [20/50], Loss: 0.1970\n",
            "Accuracy of the model on the test images: 93.47%\n",
            "Epoch [21/50]\n",
            "Epoch [21/50], Loss: 0.1876\n",
            "Accuracy of the model on the test images: 93.09%\n",
            "Epoch [22/50]\n",
            "Epoch [22/50], Loss: 0.1834\n",
            "Accuracy of the model on the test images: 93.81%\n",
            "Epoch [23/50]\n",
            "Epoch [23/50], Loss: 0.1694\n",
            "Accuracy of the model on the test images: 94.35%\n",
            "Epoch [24/50]\n",
            "Epoch [24/50], Loss: 0.1621\n",
            "Accuracy of the model on the test images: 94.8%\n",
            "Epoch [25/50]\n",
            "Epoch [25/50], Loss: 0.1503\n",
            "Accuracy of the model on the test images: 95.22%\n",
            "Epoch [26/50]\n",
            "Epoch [26/50], Loss: 0.1500\n",
            "Accuracy of the model on the test images: 94.89%\n",
            "Epoch [27/50]\n",
            "Epoch [27/50], Loss: 0.1406\n",
            "Accuracy of the model on the test images: 96.2%\n",
            "Epoch [28/50]\n",
            "Epoch [28/50], Loss: 0.1320\n",
            "Accuracy of the model on the test images: 96.36%\n",
            "Epoch [29/50]\n",
            "Epoch [29/50], Loss: 0.1258\n",
            "Accuracy of the model on the test images: 96.45%\n",
            "Epoch [30/50]\n",
            "Epoch [30/50], Loss: 0.1249\n",
            "Accuracy of the model on the test images: 96.56%\n",
            "Epoch [31/50]\n",
            "Epoch [31/50], Loss: 0.1181\n",
            "Accuracy of the model on the test images: 96.37%\n",
            "Epoch [32/50]\n",
            "Epoch [32/50], Loss: 0.1140\n",
            "Accuracy of the model on the test images: 96.36%\n",
            "Epoch [33/50]\n",
            "Epoch [33/50], Loss: 0.1068\n",
            "Accuracy of the model on the test images: 97.13%\n",
            "Epoch [34/50]\n",
            "Epoch [34/50], Loss: 0.1032\n",
            "Accuracy of the model on the test images: 97.52%\n",
            "Epoch [35/50]\n",
            "Epoch [35/50], Loss: 0.0974\n",
            "Accuracy of the model on the test images: 96.97%\n",
            "Epoch [36/50]\n",
            "Epoch [36/50], Loss: 0.0958\n",
            "Accuracy of the model on the test images: 97.11%\n",
            "Epoch [37/50]\n",
            "Epoch [37/50], Loss: 0.0904\n",
            "Accuracy of the model on the test images: 97.43%\n",
            "Epoch [38/50]\n",
            "Epoch [38/50], Loss: 0.0863\n",
            "Accuracy of the model on the test images: 96.98%\n",
            "Epoch [39/50]\n",
            "Epoch [39/50], Loss: 0.0876\n",
            "Accuracy of the model on the test images: 97.07%\n",
            "Epoch [40/50]\n",
            "Epoch [40/50], Loss: 0.0812\n",
            "Accuracy of the model on the test images: 97.55%\n",
            "Epoch [41/50]\n",
            "Epoch [41/50], Loss: 0.0784\n",
            "Accuracy of the model on the test images: 98.05%\n",
            "Epoch [42/50]\n",
            "Epoch [42/50], Loss: 0.0786\n",
            "Accuracy of the model on the test images: 97.58%\n",
            "Epoch [43/50]\n",
            "Epoch [43/50], Loss: 0.0746\n",
            "Accuracy of the model on the test images: 97.68%\n",
            "Epoch [44/50]\n",
            "Epoch [44/50], Loss: 0.0719\n",
            "Accuracy of the model on the test images: 98.03%\n",
            "Epoch [45/50]\n",
            "Epoch [45/50], Loss: 0.0727\n",
            "Accuracy of the model on the test images: 97.29%\n",
            "Epoch [46/50]\n",
            "Epoch [46/50], Loss: 0.0673\n",
            "Accuracy of the model on the test images: 98.19%\n",
            "Epoch [47/50]\n",
            "Epoch [47/50], Loss: 0.0658\n",
            "Accuracy of the model on the test images: 98.14%\n",
            "Epoch [48/50]\n",
            "Epoch [48/50], Loss: 0.0671\n",
            "Accuracy of the model on the test images: 98.28%\n",
            "Epoch [49/50]\n",
            "Epoch [49/50], Loss: 0.0618\n",
            "Accuracy of the model on the test images: 98.44%\n",
            "Epoch [50/50]\n",
            "Epoch [50/50], Loss: 0.0593\n",
            "Accuracy of the model on the test images: 98.1%\n",
            "Predictions written to kaggle_submission.csv\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Cifar10Project.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1ia_NH7kj65O1-lC5NipjNMNJMzeTR5FD\n",
        "\"\"\"\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Function to load CIFAR-10 dataset from binary pickle files\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "# Define paths to the data files\n",
        "file_paths = [\n",
        "    'data_batch_1',\n",
        "    'data_batch_2',\n",
        "    'data_batch_3',\n",
        "    'data_batch_4',\n",
        "    'data_batch_5'\n",
        "]\n",
        "\n",
        "# Detect and set the appropriate device (GPU or CPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Load and prepare the training data\n",
        "batch_data = []\n",
        "batch_label = []\n",
        "for file_path in file_paths:\n",
        "    batch = unpickle(file_path)\n",
        "    batch_data.append(batch[b'data'])\n",
        "    batch_label.append(batch[b'labels'])\n",
        "train_data = np.concatenate(batch_data)\n",
        "train_labels = np.concatenate(batch_label)\n",
        "print(train_data.shape, train_labels.shape)\n",
        "\n",
        "# Load and prepare the test data\n",
        "test_batch = unpickle('test_batch')\n",
        "test_batch_data = []\n",
        "test_batch_labels = []\n",
        "test_batch_data.append(batch[b'data'])\n",
        "test_batch_labels.append(batch[b'labels'])\n",
        "test_data = np.concatenate(test_batch_data)\n",
        "test_labels = np.concatenate(test_batch_labels)\n",
        "print(\"train_data\")\n",
        "print(train_data)\n",
        "print(\"test_data\")\n",
        "print(test_data)\n",
        "\n",
        "# Define the dataset class for CIFAR-10\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.data[index].reshape(3, 32, 32).transpose(1, 2, 0)\n",
        "        label = self.labels[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Data transformations for training and testing\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = CIFAR10Dataset(train_data, train_labels, transform=transform_train)\n",
        "test_dataset = CIFAR10Dataset(test_data, test_labels, transform=transform_test)\n",
        "\n",
        "# Data loaders for handling batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Definition of network architecture components (BasicBlock and Bottleneck)\n",
        "# Define BasicBlock and Bottleneck here, which are used in the ResNet model\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "# Define the ResNet architecture\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 32  # Reduced from 64 to adjust to CIFAR-10\n",
        "        # Additional layers and network initialization\n",
        "        # Implement the network forward pass\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
        "\n",
        "        self.layer3 = self._make_layer(block, 128, max(1, num_blocks[2]-1), stride=2)  # 减少一个block\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "          layers.append(block(self.in_planes, planes, stride))\n",
        "          self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "def resnet34():\n",
        "  return ResNet(BasicBlock,[3,4,6,3])\n",
        "# Instantiate and train the network\n",
        "model = resnet34().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters is: {total_params}\")\n",
        "if total_params > 5000000:\n",
        "    print(\"Warning: Your model has more than 5 million parameters.\")\n",
        "\n",
        "# Training loop\n",
        "\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device).long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # evaluate model\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the test images: {100 * correct / total}%')\n",
        "\n",
        "# save model\n",
        "torch.save(model.state_dict(), 'resnet18_cifar10_epoch100.pth')\n",
        "import csv\n",
        "\n",
        "# Function to write predictions to a CSV file\n",
        "def write_predictions_to_csv(test_loader, model, file_name=\"submission.csv\"):\n",
        "    model.eval()\n",
        "    ids = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, _) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            ids.extend(range(batch_idx*test_loader.batch_size, (batch_idx+1)*test_loader.batch_size))\n",
        "            labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Correct the IDs in case the last batch was smaller\n",
        "    ids = ids[:len(test_dataset)]\n",
        "\n",
        "    # Write to CSV file\n",
        "    with open(file_name, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['ID', 'Labels'])\n",
        "        for i, label in zip(ids, labels):\n",
        "            writer.writerow([i, label])\n",
        "\n",
        "    print(f\"Predictions written to {file_name}\")\n",
        "\n",
        "# Generate and save predictions to CSV\n",
        "write_predictions_to_csv(test_loader, model, \"kaggle_submission.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('kaggle_submission.csv')\n",
        "\n",
        "# Display the contents of the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zph-jPDvv1oi",
        "outputId": "6f4d081c-c98c-4482-fe15-4422d186a351"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID  Labels\n",
            "0        0       1\n",
            "1        1       8\n",
            "2        2       5\n",
            "3        3       1\n",
            "4        4       5\n",
            "...    ...     ...\n",
            "9995  9995       2\n",
            "9996  9996       6\n",
            "9997  9997       9\n",
            "9998  9998       1\n",
            "9999  9999       1\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oid52mdd48Tb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}